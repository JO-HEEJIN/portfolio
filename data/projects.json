{
  "projects": [
    {
      "id": "birth2death",
      "title": "Birth2Death",
      "subtitle": "ADHD Life Management with Gamification",
      "description": "iOS app helping ADHD users manage life through gamification and AI coaching",
      "longDescription": "Comprehensive life management platform designed specifically for individuals with ADHD. Features include task gamification with collectible characters, AI-powered habit coaching, time-boxing with gentle reminders, and progress visualization. Built with SwiftUI and integrated with GPT-4 for personalized guidance.",
      "category": "HEALTHCARE",
      "tags": ["SwiftUI", "iOS", "HealthKit", "GPT-4", "Gamification"],
      "year": 2024,
      "thumbnail": "/images/projects/birth2death-thumb.jpg",
      "images": [
        "/images/projects/birth2death-1.jpg",
        "/images/projects/birth2death-2.jpg",
        "/images/projects/birth2death-3.jpg"
      ],
      "videoUrl": "https://youtu.be/4rUfr1F2gjo?si=6w-7GPp41LtnbzJM",
      "liveDemo": null,
      "githubUrl": "https://github.com/JO-HEEJIN/birth2death",
      "highlights": [
        "Gamified task management with collectible 3D characters",
        "AI-powered habit coaching using GPT-4",
        "Gentle time-boxing with non-intrusive reminders",
        "Progress visualization and analytics",
        "Integration with Apple HealthKit"
      ],
      "techStack": [
        {
          "name": "Swift",
          "icon": "swift",
          "url": "https://swift.org"
        },
        {
          "name": "SwiftUI",
          "icon": "swiftui",
          "url": "https://developer.apple.com/xcode/swiftui/"
        },
        {
          "name": "SceneKit",
          "icon": "scenekit",
          "url": "https://developer.apple.com/scenekit/"
        },
        {
          "name": "OpenAI",
          "icon": "openai",
          "url": "https://openai.com"
        }
      ],
      "metrics": [
        {
          "label": "Task Completion Rate",
          "value": "78",
          "unit": "%"
        },
        {
          "label": "User Engagement",
          "value": "4.7",
          "unit": "/5"
        }
      ]
    },
    {
      "id": "kisan-ai",
      "title": "KisanAIAR",
      "subtitle": "Dual-Platform AR & AI Agricultural Assistant",
      "description": "Mobile AR + Desktop game platform with AI-powered crop management for precision agriculture",
      "longDescription": "KisanAI is a comprehensive dual-platform agricultural solution combining mobile AR/AI capabilities with desktop gaming and data analysis. Mobile platform features real-world AR visualization, AI-powered disease detection, and ChatGPT integration for farming advice. Desktop platform offers interactive farming simulation games and advanced data analytics dashboard. Winner of NASA Space Apps Challenge 2025, serving 5000+ farmers with multilingual support.",
      "category": "AR_VR",
      "tags": ["React Native", "Unity", "TensorFlow", "AR", "ChatGPT", "Game Dev"],
      "year": 2025,
      "thumbnail": "/images/projects/kisan-ai-thumb.jpg",
      "images": [
        "/images/projects/kisan-ai-1.jpg",
        "/images/projects/kisan-ai-2.jpg",
        "/images/projects/kisan-ai-3.jpg"
      ],
      "videoUrl": "https://youtu.be/YGJO8rUoSCs?si=-CdsNDvXrb1MtBm3",
      "liveDemo": "https://kisan-ai-one.vercel.app/",
      "githubUrl": "https://github.com/JO-HEEJIN/kisanai",
      "highlights": [
        "Winner of NASA Space Apps Challenge 2025",
        "Dual-Platform: Mobile AR/AI + Desktop Game/Analytics",
        "Mobile: Real-world AR overlay for crop health visualization",
        "Mobile: AI-powered disease detection with 93% accuracy",
        "Mobile: Integration with OpenAI GPT-4 for farming advice",
        "Desktop: Interactive farming simulation game",
        "Desktop: Advanced data analytics dashboard",
        "Weather-based yield predictions with satellite data"
      ],
      "techStack": [
        {
          "name": "React Native",
          "icon": "react",
          "url": "https://reactnative.dev"
        },
        {
          "name": "Unity",
          "icon": "unity",
          "url": "https://unity.com"
        },
        {
          "name": "TensorFlow",
          "icon": "tensorflow",
          "url": "https://tensorflow.org"
        },
        {
          "name": "OpenAI",
          "icon": "openai",
          "url": "https://openai.com"
        },
        {
          "name": "ARCore",
          "icon": "arcore",
          "url": "https://developers.google.com/ar"
        },
        {
          "name": "NASA APIs",
          "icon": "nasa",
          "url": "https://api.nasa.gov"
        }
      ],
      "metrics": [
        {
          "label": "Disease Detection Accuracy",
          "value": "93",
          "unit": "%"
        },
        {
          "label": "Active Farmers",
          "value": "5000",
          "unit": "+"
        }
      ],
      "awards": ["NASA Space Apps Challenge 2025 Winner"]
    },
    {
      "id": "coufun-ar",
      "title": "Coufun AR App",
      "subtitle": "Augmented Reality Social Platform",
      "description": "AR-powered social platform for creating and sharing immersive experiences",
      "longDescription": "Coufun is an innovative AR social platform that enables users to create, share, and experience augmented reality content in real-world environments. Winner of a national competition in South Korea, the app features location-based AR content, social sharing capabilities, and interactive AR filters. Built with Unity and ARCore/ARKit for cross-platform compatibility.",
      "category": "AR_VR",
      "tags": ["Unity", "ARCore", "ARKit", "C#", "Mobile AR"],
      "year": 2023,
      "thumbnail": "/images/projects/coufun-thumb.jpg",
      "images": [
        "/images/projects/coufun-0.jpg",
        "/images/projects/coufun-1.jpg",
        "/images/projects/coufun-2.jpg",
        "/images/projects/coufun-3.jpg"
      ],
      "videoUrl": "https://youtu.be/YNRdlhhtPDU?si=v7SlCBBbkbePVMLF",
      "notion": "https://dobito.notion.site/COUFUN-1cb3955ad0094a20b465b6fc28a1aa43?source=copy_link",
      "githubUrl": "https://github.com/101Bunker",
      "highlights": [
        "Winner of National AR Competition in South Korea",
        "Location-based AR content creation and sharing",
        "Real-time multi-user AR experiences",
        "Interactive AR filters and effects",
        "Cross-platform support (iOS & Android)",
        "Social feed with AR content discovery"
      ],
      "techStack": [
        {
          "name": "Unity",
          "icon": "unity",
          "url": "https://unity.com"
        },
        {
          "name": "ARCore",
          "icon": "arcore",
          "url": "https://developers.google.com/ar"
        },
        {
          "name": "ARKit",
          "icon": "arkit",
          "url": "https://developer.apple.com/arkit/"
        },
        {
          "name": "C#",
          "icon": "csharp",
          "url": "https://docs.microsoft.com/en-us/dotnet/csharp/"
        }
      ],
      "metrics": [
        {
          "label": "Active Users",
          "value": "15K",
          "unit": "+"
        },
        {
          "label": "AR Content Created",
          "value": "50K",
          "unit": "+"
        }
      ],
      "awards": ["National AR Competition Winner - South Korea"]
    },
    {
      "id": "vision-pro-mars-trainer",
      "title": "Vision Pro Mars Trainer",
      "subtitle": "Immersive AR Training for NASA Space Apps Challenge",
      "description": "Interactive AR training simulator for Mars surface operations using Apple Vision Pro",
      "longDescription": "Developed an immersive AR training application for NASA Space Apps Challenge 2025, enabling astronauts to practice Mars surface operations in mixed reality. The application combines real-time spatial mapping, hand tracking, and realistic physics simulation to create an authentic training environment.",
      "category": "AR_VR",
      "tags": ["SwiftUI", "RealityKit", "ARKit", "Vision Pro", "3D"],
      "year": 2025,
      "thumbnail": "/images/projects/mars-trainer-2.png",
      "images": [
        "/images/projects/mars-trainer-1.png",
        "/images/projects/mars-trainer-2.png"
      ],
      "videoUrl": null,
      "liveDemo": null,
      "githubUrl": null,
      "highlights": [
        "Real-time spatial mapping and hand gesture recognition",
        "Realistic Mars environment with accurate terrain data",
        "Multi-user collaborative training sessions",
        "Interactive 3D models with physics simulation"
      ],
      "techStack": [
        {
          "name": "Swift",
          "icon": "swift",
          "url": "https://swift.org"
        },
        {
          "name": "SwiftUI",
          "icon": "swiftui",
          "url": "https://developer.apple.com/xcode/swiftui/"
        },
        {
          "name": "RealityKit",
          "icon": "realitykit",
          "url": "https://developer.apple.com/augmented-reality/realitykit/"
        },
        {
          "name": "ARKit",
          "icon": "arkit",
          "url": "https://developer.apple.com/arkit/"
        }
      ],
      "metrics": [
        {
          "label": "Training Accuracy",
          "value": "95",
          "unit": "%"
        },
        {
          "label": "User Satisfaction",
          "value": "4.8",
          "unit": "/5"
        }
      ]
    },
    {
      "id": "venclfit",
      "title": "VENCLFIT (Watch Your Neck)",
      "subtitle": "AI-Powered Posture Tracking & Neck Health Management",
      "description": "Cervical spine health management service targeting 20-40 age group with real-time posture monitoring",
      "longDescription": "VENCLFIT is an innovative healthcare solution addressing forward head posture (text neck syndrome) in younger demographics. The service combines real-time posture tracking, AI-powered analysis, and personalized health management to prevent and treat cervical spine issues caused by prolonged device usage. Winner of the Most Excellent Award at TEU MED 2기 medical innovation competition, earning 1.5 million won in prize money. The project emerged from a 7-week medical technology innovation program featuring startup toolkit training, team projects, and expert mentoring.",
      "category": "HEALTHCARE",
      "tags": ["Healthcare", "AI", "Posture Detection", "Mobile Health", "Preventive Care"],
      "year": 2022,
      "thumbnail": "/images/projects/venclfit-thumb.jpg",
      "images": [
        "/images/projects/venclfit-1.jpg",
        "/images/projects/venclfit-2.jpg",
        "/images/projects/venclfit-3.jpg",
        "/images/projects/venclfit-4.jpg",
        "/images/projects/venclfit-5.jpg",
        "/images/projects/venclfit-6.jpg"
      ],
      "videoUrl": "https://youtu.be/vP5QW6I4D6s",
      "liveDemo": null,
      "githubUrl": null,
      "notion": "https://dobito.notion.site/VENCLFIT-08eebc1fafe64bfb88224c8f5290ae85",
      "pitchDeck": "https://docs.google.com/presentation/d/1HPey25n-0IxShbo9FWkfGE0Y8YQTvOSdCwyRBBl3xDA/edit?usp=sharing",
      "highlights": [
        "Most Excellent Award at TEU MED 2기 Competition (Prize: 1.5M won)",
        "Real-time cervical spine posture tracking and monitoring",
        "AI-powered analysis for forward head posture detection",
        "Personalized health management plans for 20-40 age demographic",
        "Preventive care solution for text neck syndrome",
        "Featured in major Korean media: E-Daily, Digital Daily, Medigatenews"
      ],
      "techStack": [
        {
          "name": "AI/ML",
          "icon": "ai",
          "url": "https://tensorflow.org"
        },
        {
          "name": "Mobile Development",
          "icon": "mobile",
          "url": "https://reactnative.dev"
        },
        {
          "name": "Computer Vision",
          "icon": "vision",
          "url": "https://opencv.org"
        },
        {
          "name": "Healthcare Tech",
          "icon": "health",
          "url": "#"
        }
      ],
      "metrics": [
        {
          "label": "Target Demographic",
          "value": "20-40",
          "unit": "세대"
        },
        {
          "label": "Prize Money",
          "value": "1.5M",
          "unit": "원"
        }
      ],
      "awards": ["TEU MED 2기 최우수상 (Most Excellent Award)"],
      "pressLinks": [
        {
          "title": "E-Daily",
          "url": "https://www.edaily.co.kr/News/Read?newsId=02663366632361392&mediaCodeNo=257"
        },
        {
          "title": "Digital Daily",
          "url": "https://www.ddaily.co.kr/page/view/2022061409360855418"
        },
        {
          "title": "Medigatenews",
          "url": "https://www.medigatenews.com/news/1788122223"
        },
        {
          "title": "Newswire",
          "url": "https://www.newswire.co.kr/newsRead.php?no=946119"
        }
      ]
    },
    {
      "id": "skin-burn-ai",
      "title": "Skin Burn AI Classification",
      "subtitle": "Medical AI for Burn Severity Assessment",
      "description": "Deep learning model for automated burn severity classification",
      "longDescription": "Medical AI application using convolutional neural networks to classify burn severity from images. Assists healthcare professionals in rapid triage and treatment planning. Trained on diverse medical datasets with 96% classification accuracy.",
      "category": "AI_ML",
      "tags": ["Python", "TensorFlow", "Medical AI", "CNN", "Healthcare"],
      "year": 2022,
      "thumbnail": "/images/projects/burn-ai-thumb.jpg",
      "images": [
        "/images/projects/burn-ai-1.jpg",
        "/images/projects/burn-ai-2.jpg",
        "/images/projects/burn-ai-3.jpg"
      ],
      "videoUrl": null,
      "liveDemo": null,
      "notionUrl": "https://dobito.notion.site/AI-cf9b0e1b19ce4ae390fd418671284eda?source=copy_link",
      "highlights": [
        "1st Place Winner - National Medical AI Competition (South Korea)",
        "96% classification accuracy for burn severity",
        "Real-time inference on mobile devices",
        "HIPAA-compliant data handling",
        "Integration with hospital EHR systems",
        "Multi-class burn severity classification"
      ],
      "techStack": [
        {
          "name": "Python",
          "icon": "python",
          "url": "https://python.org"
        },
        {
          "name": "TensorFlow",
          "icon": "tensorflow",
          "url": "https://tensorflow.org"
        },
        {
          "name": "Keras",
          "icon": "keras",
          "url": "https://keras.io"
        },
        {
          "name": "Flask",
          "icon": "flask",
          "url": "https://flask.palletsprojects.com"
        }
      ],
      "metrics": [
        {
          "label": "Classification Accuracy",
          "value": "96",
          "unit": "%"
        },
        {
          "label": "Inference Time",
          "value": "0.3",
          "unit": "s"
        }
      ],
      "awards": ["1st Place - National Medical AI Competition (South Korea)"]
    },
    {
      "id": "niaverse-funding",
      "title": "Niaverse Funding Platform",
      "subtitle": "Decentralized Crowdfunding for Creative Projects",
      "description": "Web3-powered crowdfunding platform enabling transparent project funding with blockchain technology",
      "longDescription": "Niaverse is a decentralized funding platform built on blockchain technology, enabling creators to launch campaigns and receive funding transparently. Features include smart contract-based fund management, NFT rewards for backers, milestone-based fund release, and comprehensive project analytics. Built with modern web technologies and integrated with Ethereum blockchain.",
      "category": "BLOCKCHAIN",
      "tags": ["Next.js", "Web3", "Ethereum", "Smart Contracts", "TypeScript"],
      "year": 2025,
      "thumbnail": "/images/projects/niaverse-thumb.jpg",
      "images": [
        "/images/projects/niaverse-1.jpg",
        "/images/projects/niaverse-2.jpg",
        "/images/projects/niaverse-3.jpg"
      ],
      "videoUrl": null,
      "liveDemo": "https://niaverse.org",
      "githubUrl": "https://github.com/JO-HEEJIN/niaverse-funding-platform",
      "highlights": [
        "Decentralized crowdfunding with smart contracts",
        "NFT-based rewards system for backers",
        "Milestone-based fund release mechanism",
        "Real-time project analytics dashboard",
        "Transparent on-chain transaction history",
        "Multi-wallet support (MetaMask, WalletConnect)"
      ],
      "techStack": [
        {
          "name": "Next.js",
          "icon": "nextjs",
          "url": "https://nextjs.org"
        },
        {
          "name": "TypeScript",
          "icon": "typescript",
          "url": "https://typescriptlang.org"
        },
        {
          "name": "Ethereum",
          "icon": "ethereum",
          "url": "https://ethereum.org"
        },
        {
          "name": "Solidity",
          "icon": "solidity",
          "url": "https://soliditylang.org"
        },
        {
          "name": "Web3.js",
          "icon": "web3",
          "url": "https://web3js.org"
        }
      ],
      "metrics": [
        {
          "label": "Total Campaigns",
          "value": "150",
          "unit": "+"
        },
        {
          "label": "Funds Raised",
          "value": "$2M",
          "unit": "+"
        }
      ]
    },
    {
      "id": "ux-design-portfolio",
      "title": "UX Design & Brand Identity",
      "subtitle": "Equity-Focused Design Philosophy with Google UX Certificate",
      "description": "Comprehensive UX design portfolio featuring brand identity, mobile UI/UX, and equity-focused design work",
      "longDescription": "A collection of design work emphasizing equity-focused and inclusive design principles. Completed Google UX Design Certificate (Coursera) and applied learnings to real-world projects including the UNDERDOG project for chronic pain patients. Design philosophy centers on 'solve for one, extend to many' - creating solutions that uplift historically underrepresented groups. Portfolio includes brand identity design (VENCLFIT, UNDERDOG, HEEJIN), mobile app UI/UX (KKUDUCK), and visual design work.",
      "category": "DESIGN",
      "tags": ["UX Design", "UI Design", "Figma", "Brand Identity", "Inclusive Design", "Adobe Creative Suite"],
      "year": 2021,
      "thumbnail": "/images/projects/ux-design-thumb.jpg",
      "images": [
        "/images/projects/ux-design-1.jpg",
        "/images/projects/ux-design-2.jpg",
        "/images/projects/ux-design-3.jpg",
        "/images/projects/ux-design-4.gif"
      ],
      "videoUrl": null,
      "liveDemo": "https://velog.io/@midmost/Introduction-to-Logic",
      "githubUrl": null,
      "highlights": [
        "Google UX Design Certificate (Coursera)",
        "Equity-focused design philosophy: designing for historically underrepresented groups",
        "UNDERDOG Project: Products for people with chronic pain and disabilities",
        "Brand Identity Design: VENCLFIT, UNDERDOG, HEEJIN logos",
        "Mobile App UI/UX: KKUDUCK subscription management interface",
        "Visual Design: INTOEFL poster design",
        "Inclusive design principle: 'solve for one, extend to many'"
      ],
      "techStack": [
        {
          "name": "Figma",
          "icon": "figma",
          "url": "https://figma.com"
        },
        {
          "name": "Adobe Illustrator",
          "icon": "illustrator",
          "url": "https://adobe.com/illustrator"
        },
        {
          "name": "Adobe Photoshop",
          "icon": "photoshop",
          "url": "https://adobe.com/photoshop"
        },
        {
          "name": "Blender",
          "icon": "blender",
          "url": "https://blender.org"
        }
      ],
      "metrics": [
        {
          "label": "Design Projects",
          "value": "15",
          "unit": "+"
        },
        {
          "label": "Brand Identities",
          "value": "6",
          "unit": ""
        }
      ],
      "awards": ["Google UX Design Professional Certificate"]
    },
    {
      "id": "getn-show",
      "title": "GetnShow",
      "subtitle": "Interactive Story Platform with Real-time Collaboration",
      "description": "Platform for creating and sharing interactive web experiences",
      "longDescription": "Modern web platform enabling creators to build and share interactive storytelling experiences. Features real-time collaboration, rich media embedding, analytics, and monetization tools. Built with Next.js 14 and optimized for performance.",
      "category": "WEB",
      "tags": ["Next.js", "React", "TypeScript", "Tailwind", "Vercel"],
      "year": 2025,
      "thumbnail": "/images/projects/getn-show-thumb.jpg",
      "images": [
        "/images/projects/getn-show-1.jpg"
      ],
      "videoUrl": null,
      "liveDemo": "https://www.getn.show/",
      "githubUrl": null,
      "highlights": [
        "Real-time collaborative editing",
        "Rich media support (video, audio, 3D)",
        "Performance-optimized with Next.js 14",
        "Built-in analytics and engagement metrics",
        "Creator monetization tools"
      ],
      "techStack": [
        {
          "name": "Next.js",
          "icon": "nextjs",
          "url": "https://nextjs.org"
        },
        {
          "name": "React",
          "icon": "react",
          "url": "https://react.dev"
        },
        {
          "name": "TypeScript",
          "icon": "typescript",
          "url": "https://typescriptlang.org"
        },
        {
          "name": "Tailwind CSS",
          "icon": "tailwind",
          "url": "https://tailwindcss.com"
        }
      ],
      "metrics": [
        {
          "label": "Page Load Time",
          "value": "1.2",
          "unit": "s"
        },
        {
          "label": "Lighthouse Score",
          "value": "98",
          "unit": "/100"
        }
      ]
    },
    {
      "id": "neverforget",
      "title": "NeverForget",
      "subtitle": "AI Memory Assistant with Infinite Context",
      "description": "iOS AI assistant that never forgets - powered by Long Context + Prompt Caching architecture",
      "longDescription": "NeverForget is an iOS AI memory assistant built on the promise of 'AI that never forgets'. Instead of using traditional RAG (which can miss relevant context), it implements Long Context architecture that passes the entire conversation history to Claude, combined with Anthropic's Prompt Caching for 90% cost reduction. The app also integrates Gemini Vision for fast image analysis.",
      "category": "AI_ML",
      "tags": ["Swift", "iOS", "Claude API", "Prompt Caching", "Gemini", "PostgreSQL"],
      "year": 2024,
      "thumbnail": "/images/projects/neverforget-thumb.png",
      "images": [],
      "videoUrl": null,
      "liveDemo": null,
      "githubUrl": "https://github.com/JO-HEEJIN/NeverForget",
      "highlights": [
        "Long Context architecture - 100% context retention, no search failures",
        "Claude Prompt Caching - 90% API cost reduction",
        "Gemini 2.0 Flash for fast image analysis (26s → 2s)",
        "96-99% cache hit rate in production",
        "Privacy-first design with secure token handling",
        "Architected for future Azure self-hosted LLM with real CAG"
      ],
      "techStack": [
        {
          "name": "Swift",
          "icon": "swift",
          "url": "https://swift.org"
        },
        {
          "name": "Claude API",
          "icon": "anthropic",
          "url": "https://anthropic.com"
        },
        {
          "name": "Gemini",
          "icon": "google",
          "url": "https://ai.google.dev"
        },
        {
          "name": "PostgreSQL",
          "icon": "postgresql",
          "url": "https://postgresql.org"
        }
      ],
      "metrics": [
        {
          "label": "Cache Hit Rate",
          "value": "96-99",
          "unit": "%"
        },
        {
          "label": "Cost Reduction",
          "value": "90",
          "unit": "%"
        }
      ]
    },
    {
      "id": "nvidia-devtech-portfolio",
      "title": "NVIDIA DevTech Portfolio",
      "subtitle": "GPU Computing & AI Optimization Projects",
      "description": "Comprehensive portfolio for NVIDIA DevTech internship - TensorRT, CUDA, Triton Inference Server",
      "longDescription": "A collection of 8 portfolio projects demonstrating expertise in NVIDIA GPU computing technologies. Includes TensorRT optimization with layer fusion and precision calibration, CUDA matrix multiplication, YOLOv8 deployment, Triton Inference Server multi-model serving, INT8 quantization, and healthcare VLM deployment for medical imaging.",
      "category": "AI_ML",
      "tags": ["CUDA", "TensorRT", "Triton", "PyTorch", "ONNX", "GPU Computing"],
      "year": 2025,
      "thumbnail": "/images/projects/nvidia-thumb.png",
      "images": [],
      "videoUrl": null,
      "liveDemo": "https://www.kaggle.com/code/dubito/pytorch-to-tensorrt-optimization",
      "githubUrl": "https://github.com/JO-HEEJIN/nvidia-devtech-portfolio",
      "highlights": [
        "TensorRT optimization with layer fusion and precision calibration",
        "CUDA matrix multiplication demonstrating parallel computing",
        "YOLOv8 TensorRT deployment for real-time inference",
        "Triton Inference Server with dynamic batching",
        "INT8 quantization with minimal accuracy loss",
        "Healthcare VLM deployment for medical imaging"
      ],
      "techStack": [
        {
          "name": "CUDA",
          "icon": "nvidia",
          "url": "https://developer.nvidia.com/cuda-toolkit"
        },
        {
          "name": "TensorRT",
          "icon": "nvidia",
          "url": "https://developer.nvidia.com/tensorrt"
        },
        {
          "name": "PyTorch",
          "icon": "pytorch",
          "url": "https://pytorch.org"
        },
        {
          "name": "Triton",
          "icon": "nvidia",
          "url": "https://developer.nvidia.com/nvidia-triton-inference-server"
        }
      ],
      "metrics": [
        {
          "label": "Portfolio Projects",
          "value": "8",
          "unit": ""
        },
        {
          "label": "Focus Areas",
          "value": "GPU",
          "unit": "Optimization"
        }
      ]
    },
    {
      "id": "life-navigator",
      "title": "Life Navigator",
      "subtitle": "Personal AI Productivity Assistant",
      "description": "NASA-inspired architecture for personal productivity optimization using Google APIs",
      "longDescription": "Life Navigator applies NASA's Farm Navigators 4-layer data-driven architecture to personal productivity. Just as Farm Navigators uses satellite data (SMAP, MODIS, Landsat) for soil health analysis, Life Navigator uses personal APIs (Gmail, Calendar) for stress and schedule analysis. Features serverless Vercel functions, Redis token storage, and AI-powered life optimization recommendations.",
      "category": "AI_ML",
      "tags": ["Node.js", "Google APIs", "Vercel", "OAuth 2.0", "Redis", "Serverless"],
      "year": 2024,
      "thumbnail": "/images/projects/life-navigator-thumb.png",
      "images": [],
      "videoUrl": null,
      "liveDemo": "https://life-navigator-ten.vercel.app",
      "githubUrl": "https://github.com/JO-HEEJIN/life-navigator",
      "highlights": [
        "NASA Farm Navigators architecture pattern applied to personal productivity",
        "Real-time Gmail stress analysis and Calendar health tracking",
        "Google OAuth 2.0 with secure token handling",
        "Vercel Edge Functions for global performance",
        "Upstash Redis for OAuth token persistence",
        "AI-powered personalized recommendations"
      ],
      "techStack": [
        {
          "name": "Node.js",
          "icon": "nodejs",
          "url": "https://nodejs.org"
        },
        {
          "name": "Google APIs",
          "icon": "google",
          "url": "https://developers.google.com/apis-explorer"
        },
        {
          "name": "Vercel",
          "icon": "vercel",
          "url": "https://vercel.com"
        },
        {
          "name": "Redis",
          "icon": "redis",
          "url": "https://redis.io"
        }
      ],
      "metrics": [
        {
          "label": "Architecture Layers",
          "value": "4",
          "unit": ""
        },
        {
          "label": "APIs Integrated",
          "value": "Gmail + Calendar",
          "unit": ""
        }
      ]
    }
  ]
}
